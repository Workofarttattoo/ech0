[
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245950"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245965"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245968"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245970"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245972"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245974"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245977"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245984"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245987"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245990"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245992"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.245994"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246006"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246008"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246010"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246012"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246014"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246016"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246018"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246020"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246022"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246035"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246037"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246039"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246041"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246043"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246045"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246047"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246049"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246051"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246053"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246055"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246057"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246059"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246062"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246065"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246068"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246071"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246077"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246080"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246083"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246087"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246090"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246093"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246096"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246099"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246102"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246106"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246109"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246112"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246115"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246118"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246121"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246123"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246125"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246127"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246129"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246131"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246133"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246135"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246137"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246139"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246141"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246148"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246150"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246153"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246155"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246157"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246159"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246161"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246163"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246165"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246167"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246169"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246171"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246173"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246175"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246177"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246179"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246182"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246185"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246188"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246191"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246194"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246198"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246201"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246203"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246207"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246210"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246213"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246217"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246220"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246224"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246226"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246228"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246230"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246233"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246234"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246236"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246238"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246240"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246243"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246245"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246247"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246249"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246250"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246252"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246254"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246256"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246259"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246261"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246263"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246265"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246267"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246269"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246270"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246272"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246274"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246276"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246278"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246280"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246282"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246284"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246286"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246288"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246290"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246292"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246294"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246296"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246298"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246300"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246302"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246304"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246306"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246308"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246310"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246312"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246314"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246316"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246318"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246320"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246322"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246324"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246326"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246328"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246330"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246332"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246333"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246336"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246338"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246340"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246342"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246344"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246346"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246348"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246350"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246352"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246354"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246356"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246358"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246360"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246362"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246364"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246366"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246368"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246370"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246372"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246374"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246376"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246378"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246380"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246382"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246384"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246386"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246388"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246390"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246391"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246394"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246397"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246399"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246401"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246403"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246405"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246407"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246409"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246411"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246413"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246415"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246417"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246419"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246421"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246423"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246425"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246426"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246428"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246430"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246432"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246436"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246438"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246440"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246442"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246445"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246446"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246448"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246450"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246452"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246454"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246456"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246459"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246460"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246462"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246464"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246466"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246468"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246470"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246472"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246474"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246476"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246478"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246480"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246482"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246484"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246486"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246488"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246492"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246494"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246496"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246498"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246500"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246502"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246503"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246505"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246507"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246510"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246512"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246514"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246516"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246518"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246520"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246522"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246524"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246526"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246528"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246530"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246532"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246534"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246535"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246537"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246539"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246541"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246543"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246545"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246550"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246552"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246554"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246556"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246558"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246560"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246562"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246564"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246566"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246568"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246570"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246572"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246574"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246576"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246578"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246580"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246582"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246584"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246586"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246588"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246590"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246592"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246594"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246596"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246598"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246600"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246602"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246604"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246606"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246608"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246610"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246612"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246616"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246618"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246620"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246622"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246624"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246626"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246628"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246630"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246632"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246634"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246636"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246637"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246639"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246641"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246643"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246645"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246647"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246649"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246651"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246653"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246655"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246657"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246659"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246661"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246663"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246665"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246667"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246669"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246671"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246673"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246675"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246677"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246679"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246681"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246683"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246685"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246687"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246689"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246691"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246693"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246695"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246697"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246699"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246700"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246703"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246705"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246707"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246709"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246711"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246713"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246714"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246716"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246718"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246720"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246722"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246724"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246726"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246728"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246730"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246732"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246734"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246736"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246738"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246740"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246742"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246744"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246746"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246748"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246750"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246752"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246754"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246756"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246758"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246760"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246762"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246764"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246766"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246768"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246770"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246772"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246774"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246776"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246778"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246780"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246782"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246784"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246786"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246788"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246790"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246792"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246794"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246796"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246798"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246800"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246826"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246828"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246830"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246832"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246834"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246836"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246838"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246840"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246842"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246844"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246846"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246848"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246850"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246852"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246854"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246856"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246857"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246859"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246861"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246863"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246865"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246867"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246870"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246872"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246874"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246876"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246878"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246880"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246882"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246884"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246886"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246888"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246890"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246892"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246894"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246896"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246898"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246900"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246902"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246903"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246905"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246907"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246909"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246911"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246913"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246915"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246917"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246919"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246921"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246923"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246925"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246927"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246929"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246931"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246933"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246935"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246937"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246939"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246941"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246943"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246945"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246947"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246949"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246950"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246952"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246954"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246956"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246959"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246961"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246962"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246964"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246966"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246968"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246970"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246972"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246974"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246976"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246979"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246981"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246983"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246985"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246987"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246988"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246990"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246992"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246994"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246996"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.246998"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247000"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247002"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247004"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247006"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247008"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247010"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247012"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247014"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247016"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247018"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247020"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247032"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247034"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247036"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247038"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247040"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247042"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247044"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247046"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247048"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247050"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247052"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247054"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247056"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247058"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247060"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247062"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247064"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247066"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247068"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247069"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247071"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247073"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247075"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247077"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247079"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247081"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247083"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247085"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247087"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247089"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247091"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247093"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247097"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247099"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247101"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247103"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247105"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247107"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247109"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247111"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247113"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247115"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247117"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247119"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247121"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247123"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247125"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247127"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247129"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247131"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247133"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247134"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247136"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247138"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247140"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247142"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247147"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247149"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247151"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247153"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247155"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247159"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247162"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247165"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247171"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247175"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247178"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247181"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247185"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247188"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247191"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247194"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247198"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247201"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247203"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247205"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247207"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247209"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247211"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247213"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247215"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247217"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247219"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247221"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247223"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247225"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247227"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247229"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247230"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247232"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247234"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247236"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247238"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247240"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247242"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247244"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247246"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247248"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247250"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247252"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247254"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247256"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247258"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247260"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247262"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247264"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247266"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247268"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247270"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247272"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247274"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247276"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247278"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247280"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247282"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247284"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247286"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247288"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247290"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247292"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247294"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247296"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247298"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247300"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247302"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247304"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247306"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247308"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247310"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247312"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247314"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247316"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247318"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247320"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247322"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247324"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247325"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247327"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247330"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247332"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247334"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247336"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247338"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247340"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247342"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247344"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247345"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247347"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247349"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247351"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247353"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247355"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247357"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247359"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247361"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247363"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247365"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247367"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247369"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247371"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247373"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247375"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247377"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247379"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247381"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247383"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247385"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247387"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247389"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247391"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247393"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247397"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247399"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247401"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247403"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247405"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247407"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247409"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247410"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247412"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247414"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247416"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247418"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247420"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247422"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247424"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247426"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247428"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247430"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247432"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247434"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247436"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247438"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247440"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247442"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247444"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247446"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247448"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247450"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247452"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247454"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247456"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247458"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247460"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247462"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247464"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247466"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247468"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247470"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247472"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247474"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247476"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247478"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247480"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247482"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247484"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247486"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247488"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247490"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247492"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247494"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247496"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247498"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247500"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247502"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247503"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247505"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247507"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247509"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247511"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247513"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247515"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247517"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247519"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247521"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247523"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247525"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247527"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247529"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247531"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247533"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247535"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247537"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247539"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247541"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247543"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247545"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247547"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247548"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247550"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247552"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247554"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247570"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247572"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247574"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247576"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247578"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247580"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247582"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247584"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247586"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247588"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247590"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247592"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247594"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247596"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247598"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247600"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247602"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247604"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247606"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247608"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247610"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247612"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247614"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247616"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247618"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247620"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247622"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247624"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247626"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247628"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247630"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247631"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247634"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247636"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247638"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247639"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247641"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247644"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247646"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247648"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247650"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247651"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247653"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247655"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247657"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247659"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247661"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247663"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247665"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247667"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247670"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247672"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247674"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247676"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247678"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247680"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247682"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247684"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247686"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247688"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247690"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247692"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247694"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247696"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247698"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247700"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247702"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247704"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247706"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247708"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247710"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247712"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247714"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247716"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247718"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247720"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247722"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247724"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247726"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247727"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247730"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247732"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247734"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247736"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247738"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247740"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247742"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247743"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247745"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247747"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247749"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247751"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247753"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247755"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247757"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247759"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247761"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247763"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247765"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247768"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247769"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247772"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247774"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247775"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247777"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247779"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247781"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247784"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247786"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247787"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247790"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247792"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247794"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247795"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247797"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247799"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247801"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247803"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247805"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247807"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247809"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247811"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247813"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247815"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247817"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247819"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247821"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247823"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247825"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247827"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247829"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247831"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247833"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247835"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247837"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247839"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247841"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247843"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247845"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247847"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247849"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247851"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247853"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247855"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247857"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247859"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247861"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247863"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247865"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247866"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247869"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247871"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247873"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247875"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247876"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247878"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247880"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247882"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247884"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247886"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247888"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247890"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247892"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247894"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247896"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247898"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247900"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247902"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247904"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247906"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247908"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247910"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247912"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247914"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247916"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247918"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247920"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247922"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247924"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247926"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247928"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247930"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247932"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247934"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247936"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247938"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247940"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247942"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247944"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247946"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247947"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247949"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247951"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247953"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247955"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247957"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247959"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247961"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247963"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247965"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247967"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247969"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247971"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247973"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247975"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247977"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247979"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247981"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247983"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247985"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247987"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247989"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247991"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247993"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247995"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247997"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.247999"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248001"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248003"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248005"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248007"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248009"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248011"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248013"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248015"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248017"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248019"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248021"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248023"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248033"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248035"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248037"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248039"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248041"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248043"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248045"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248047"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248049"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248051"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248053"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248055"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248057"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248059"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248061"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248063"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248065"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248067"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248069"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248071"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248073"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248075"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248077"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248079"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248081"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248083"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248085"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248087"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248089"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248091"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248093"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248095"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248097"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248099"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248101"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248102"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248104"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248106"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248108"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248110"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248112"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248114"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248116"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248119"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248121"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248123"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248124"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248126"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248128"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248130"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248132"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248134"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248136"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248138"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248140"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248142"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248147"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248149"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248151"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248153"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248155"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248157"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248159"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248161"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248163"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248165"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248167"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248169"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248171"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248173"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248175"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248177"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248179"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248181"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248183"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248185"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248187"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248189"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248191"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248193"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248195"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248197"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248199"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248201"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248203"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248205"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248207"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248209"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248211"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248213"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248215"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248217"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248219"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248221"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248223"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248225"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248227"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248229"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248231"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248232"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248234"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248236"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248239"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248242"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248245"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248249"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248252"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248255"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248258"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248261"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248265"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248268"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248271"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248275"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248278"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248280"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248282"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248284"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248286"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248288"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248290"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248306"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248308"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248310"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248312"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248314"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248316"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248318"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248320"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248322"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248324"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248326"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248328"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248330"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248332"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248334"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248336"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248338"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248340"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248342"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248344"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248346"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248348"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248350"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248352"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248354"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248356"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248358"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248360"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248362"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248364"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248366"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248368"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248370"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248372"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248374"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248376"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248378"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248380"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248382"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248384"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248386"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248388"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248390"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248392"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248395"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248398"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248400"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248402"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248403"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248405"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248407"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248409"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248412"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248414"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248415"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248417"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248419"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248421"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248423"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248425"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248427"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248429"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248431"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248433"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248435"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248437"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248439"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248441"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248443"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248445"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248447"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248449"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248451"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248453"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248455"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248457"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248459"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248461"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248463"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248465"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248467"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248469"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248471"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248472"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248474"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248476"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248478"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248480"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248482"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248484"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248486"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248488"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248490"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248492"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248494"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248496"
    }
  },
  {
    "instruction": "What is regularization and why is it important?",
    "input": "",
    "output": "Regularization adds constraints to model parameters to prevent overfitting. L1 (Lasso) and L2 (Ridge) regularization penalize large weights, forcing simpler models that generalize better to unseen data.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248498"
    }
  },
  {
    "instruction": "Explain the bias-variance tradeoff.",
    "input": "",
    "output": "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias = underfitting (model too simple). High variance = overfitting (model too complex). The optimal model balances both.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248500"
    }
  },
  {
    "instruction": "Explain cross-validation and its importance.",
    "input": "",
    "output": "Cross-validation splits data into multiple folds for training/testing. It provides more reliable performance estimates than a single train-test split and helps detect overfitting.",
    "domain": "ai_ml",
    "category": "machine_learning_theory",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248502"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248506"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248508"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248510"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248512"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248514"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248516"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248518"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248520"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248522"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248524"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248526"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248528"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248530"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248532"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248534"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248536"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248538"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248540"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248541"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248543"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248545"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248547"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248549"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248551"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248553"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248555"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248557"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248559"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248561"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248563"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248565"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248567"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248569"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248570"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248572"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248575"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248577"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248579"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248581"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248586"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248588"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248589"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248591"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248593"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248596"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248597"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248600"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248601"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248603"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248605"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248607"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248609"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248611"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248613"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248615"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248617"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248619"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248621"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248623"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248625"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248627"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248629"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248631"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248633"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248635"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248637"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248639"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248642"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248644"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248646"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248650"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248652"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248654"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248656"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248658"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248660"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248662"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248664"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248666"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248668"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248669"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248671"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248673"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248675"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248677"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248679"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248681"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248683"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248685"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248687"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248689"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248691"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248693"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248695"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248697"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248699"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248701"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248703"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248705"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248707"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248709"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248711"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248715"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248717"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248719"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248721"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248723"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248725"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248727"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248729"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248733"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248735"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248737"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248739"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248741"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248743"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248745"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248747"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248749"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248751"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248753"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248755"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248757"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248758"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248760"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248762"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248764"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248766"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248768"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248770"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248772"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248774"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248776"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248778"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248790"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248794"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248796"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248798"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248800"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248801"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248803"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248805"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248807"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248809"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248811"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248813"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248815"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248817"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248819"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248821"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248823"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248825"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248827"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248828"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248830"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248832"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248834"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248836"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248838"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248840"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248846"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248848"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248850"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248852"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248854"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248856"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248861"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248863"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248865"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248867"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248869"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248871"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248873"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248875"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248877"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248879"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248881"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248883"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248885"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248887"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248889"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248891"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248893"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248895"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248897"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248899"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248903"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248905"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248907"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248909"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248911"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248913"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248917"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248919"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248921"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248923"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248925"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248928"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248930"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248932"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248934"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248936"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248938"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248940"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248942"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248944"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248946"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248948"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248950"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248952"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248954"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248956"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248960"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248962"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248964"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248966"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248968"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248970"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248971"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248973"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248975"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248977"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248979"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248981"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248985"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248987"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248989"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248991"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248993"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248997"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.248999"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249001"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249003"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249005"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249007"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249009"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249011"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249015"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249017"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249019"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249021"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249023"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249032"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249034"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249036"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249038"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249039"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249041"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249043"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249045"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249047"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249063"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249065"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249067"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249069"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249070"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249075"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249077"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249079"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249081"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249083"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249086"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249090"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249092"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249094"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249096"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249098"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249100"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249102"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249104"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249106"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249108"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249110"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249112"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249114"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249116"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249118"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249120"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249121"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249123"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249125"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249127"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249129"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249131"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249133"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249135"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249137"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249139"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249148"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249150"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249152"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249154"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249156"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249160"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249162"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249164"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249166"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249168"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249170"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249172"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249174"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249176"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249178"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249180"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249181"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249184"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249186"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249187"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249189"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249191"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249193"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249195"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249197"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249199"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249203"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249205"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249207"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249209"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249211"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249216"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249218"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249220"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249222"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249224"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249228"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249230"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249232"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249234"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249236"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249238"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249240"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249242"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249244"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249246"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249248"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249250"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249251"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249253"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249255"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249259"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249261"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249263"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249265"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249267"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249269"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249271"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249273"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249275"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249277"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249279"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249281"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249285"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249287"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249289"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249291"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249292"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249296"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249298"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249300"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249302"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249304"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249306"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249308"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249310"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249315"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249317"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249319"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249322"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249326"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249329"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249333"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249336"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249339"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249342"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249346"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249349"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249352"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249356"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249359"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249362"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249364"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249366"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249367"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249372"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249374"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249376"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249378"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249380"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249383"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249385"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249389"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249391"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249393"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249397"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249399"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249401"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249403"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249405"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249407"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249409"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249411"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249413"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249415"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249417"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249419"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249421"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249423"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249425"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249427"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249429"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249431"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249433"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249435"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249437"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249438"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249442"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249446"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249448"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249450"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249452"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249456"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249458"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249460"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249462"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249464"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249466"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249468"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249470"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249472"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249474"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249476"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249478"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249480"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249482"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249484"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249486"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249488"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249490"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249492"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249495"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249496"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249500"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249502"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249504"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249506"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249508"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249510"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249514"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249516"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249518"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249520"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249524"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249526"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249528"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249530"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249532"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249534"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249535"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249537"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249539"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249541"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249543"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249545"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249547"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249549"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249551"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249556"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249558"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249560"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249562"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249564"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249566"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249568"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249570"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249572"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249574"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249576"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249578"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249580"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249584"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249586"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249588"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249590"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249594"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249596"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249598"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249600"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249602"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249604"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249606"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249608"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249610"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249613"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249615"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249617"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249619"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249621"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249623"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249625"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249627"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249629"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249631"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249633"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249635"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249637"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249639"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249641"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249643"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249645"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249647"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249649"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249653"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249655"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249656"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249658"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249662"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249664"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249666"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249670"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249672"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249674"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249676"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249678"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249680"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249682"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249684"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249686"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249688"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249690"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249692"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249694"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249696"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249698"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249700"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249702"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249704"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249706"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249708"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249709"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249711"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249713"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249715"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249717"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249723"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249725"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249727"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249729"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249733"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249735"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249737"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249738"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249740"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249742"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249744"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249746"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249748"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249750"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249752"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249754"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249756"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249758"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249760"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249762"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249764"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249766"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249768"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249770"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249771"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249775"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249777"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249779"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249781"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249783"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249785"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249788"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249790"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249792"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249794"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249798"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249800"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249802"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249804"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249806"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249808"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249810"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249812"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249814"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249816"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249818"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249820"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249822"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249824"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249826"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249828"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249831"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249833"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249835"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249837"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249839"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249841"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249843"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249863"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249865"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249867"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249869"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249871"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249875"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249877"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249879"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249881"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249886"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249888"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249890"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249892"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249894"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249896"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249898"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249900"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249902"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249904"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249908"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249910"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249912"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249913"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249915"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249917"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249919"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249921"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249923"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249925"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249927"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249929"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249931"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249933"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249935"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249937"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249939"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249941"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249945"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249947"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249949"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249951"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249955"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249956"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249958"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249962"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249964"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249966"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249968"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249970"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249972"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249974"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249976"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249978"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249980"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249982"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249984"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249986"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249988"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249990"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249992"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249994"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249996"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.249997"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250000"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250001"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250003"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250005"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250007"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250009"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250015"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250017"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250019"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250021"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250031"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250033"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250035"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250037"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250039"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250041"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250043"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250045"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250047"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250049"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250051"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250053"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250055"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250057"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250059"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250061"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250063"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250065"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250067"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250069"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250071"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250073"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250077"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250079"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250081"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250083"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250085"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250087"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250091"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250093"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250095"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250098"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250100"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250102"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250104"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250106"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250108"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250110"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250112"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250114"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250116"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250118"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250120"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250122"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250124"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250126"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250128"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250130"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250134"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250136"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250138"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250140"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250142"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250147"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250149"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250151"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250153"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250155"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250157"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250159"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250163"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250165"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250167"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250171"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250173"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250175"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250177"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250179"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250181"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250183"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250186"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250188"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250190"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250201"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250203"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250205"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250207"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250209"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250211"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250213"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250215"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250217"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250219"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250221"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250223"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250225"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250227"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250229"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250231"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250233"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250235"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250237"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250242"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250244"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250246"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250250"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250252"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250254"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250257"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250259"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250261"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250263"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250265"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250267"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250269"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250271"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250273"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250275"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250277"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250279"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250281"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250283"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250285"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250287"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250289"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250291"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250293"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250295"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250297"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250299"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250301"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250303"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250305"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250307"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250312"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250314"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250316"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250320"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250322"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250324"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250325"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250327"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250329"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250331"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250333"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250335"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250337"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250339"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250341"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250343"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250345"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250347"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250349"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250351"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250353"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250355"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250357"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250359"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250361"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250363"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250367"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250369"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250371"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250373"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250375"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250379"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250381"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250383"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250386"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250388"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250390"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250392"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250395"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250398"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250402"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250405"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250409"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250412"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250415"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250418"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250421"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250424"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250428"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250431"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250434"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250440"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250443"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250445"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250448"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250450"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250451"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250453"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250455"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250457"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250459"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250461"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250463"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250467"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250469"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250471"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250475"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250477"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250479"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250481"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250483"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250485"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250487"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250489"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250491"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250493"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250496"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250498"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250500"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250502"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250504"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250506"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250508"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250510"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250512"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250514"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250516"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250518"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250520"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250522"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250524"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250526"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250528"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250530"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250532"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250536"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250538"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250539"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250543"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250545"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250547"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250549"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250554"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250556"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250558"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250560"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250562"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250564"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250566"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250568"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250570"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250572"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250574"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250576"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250578"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250580"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250582"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250583"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250585"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250587"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250589"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250591"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250593"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250595"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250597"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250599"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250601"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250605"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250609"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250611"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250615"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250617"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250619"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250620"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250622"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250624"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250626"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250628"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250630"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250632"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250634"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250636"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250638"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250640"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250642"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250644"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250646"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250648"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250650"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250652"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250654"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250656"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250658"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250675"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250677"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250679"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250681"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250683"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250685"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250689"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250691"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250695"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250697"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250699"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250701"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250703"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250705"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250707"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250709"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250711"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250712"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250714"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250716"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250718"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250720"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250722"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250724"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250726"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250730"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250732"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250734"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250736"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250738"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250740"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250742"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250744"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250746"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250748"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250749"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250752"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250753"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250757"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250759"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250763"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250765"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250767"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250769"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250771"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250773"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250775"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250777"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250779"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250781"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250783"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250786"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250788"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250790"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250792"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250794"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250796"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250798"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250800"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250802"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250804"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250806"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250808"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250810"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250812"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250814"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250816"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250818"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250820"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250822"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250825"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250827"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250831"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250833"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250835"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250837"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250839"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250843"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250845"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250847"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250849"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250851"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250853"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250855"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250857"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250858"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250860"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250862"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250864"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250866"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250868"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250870"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250872"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250874"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250876"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250878"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250880"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250882"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250884"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250886"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250888"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250890"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250896"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250899"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250903"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250905"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250906"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250908"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250910"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250912"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250914"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250916"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250918"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250920"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250922"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250924"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250926"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250928"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250930"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250932"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250934"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250936"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250938"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250940"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250942"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250944"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250946"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250949"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250951"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250953"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250955"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250957"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250959"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250963"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250965"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250968"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250970"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250972"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250974"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250976"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250978"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250980"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250982"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250984"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250986"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250988"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250990"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250992"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250994"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250996"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.250998"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251000"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251002"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251006"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251008"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251010"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251012"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251013"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251015"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251017"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251019"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251021"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251023"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251032"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251034"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251038"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251040"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251044"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251046"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251048"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251050"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251051"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251053"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251055"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251057"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251059"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251061"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251063"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251065"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251067"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251069"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251072"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251074"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251076"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251078"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251080"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251082"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251084"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251085"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251088"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251090"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251091"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251093"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251095"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251097"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251099"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251101"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251105"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251107"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251111"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251113"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251115"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251117"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251119"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251121"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251123"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251125"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251127"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251129"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251131"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251133"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251135"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251137"
    }
  },
  {
    "instruction": "What are the main components of a Transformer?",
    "input": "",
    "output": "Transformers use Self-Attention, Multi-Head Attention, Feed-Forward Networks, Positional Encoding, and Layer Normalization. These enable parallel processing of sequences and capture long-range dependencies effectively.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251139"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251141"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251146"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251147"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251149"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251151"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251153"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251155"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251157"
    }
  },
  {
    "instruction": "Compare RNNs, LSTMs, and GRUs.",
    "input": "",
    "output": "RNNs process sequences sequentially but suffer from vanishing gradients. LSTMs use cell states and gates to maintain long-term dependencies. GRUs are simpler than LSTMs with fewer parameters.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251159"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251161"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251163"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251165"
    }
  },
  {
    "instruction": "Explain CNNs and when to use them.",
    "input": "",
    "output": "Convolutional Neural Networks use filters to extract spatial features. They're ideal for images (translation invariance), video, and spatial data due to parameter sharing and local connectivity.",
    "domain": "ai_ml",
    "category": "deep_learning_architectures",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251167"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251170"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251172"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251175"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251177"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251179"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251181"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251183"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251185"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251187"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251189"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251191"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251193"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251195"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251197"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251199"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251201"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251203"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251205"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251207"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251209"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251211"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251212"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251214"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251216"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251218"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251220"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251222"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251224"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251226"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251228"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251230"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251232"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251234"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251236"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251238"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251240"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251242"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251244"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251246"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251248"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251250"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251252"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251254"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251256"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251258"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251260"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251262"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251263"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251265"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251267"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251269"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251271"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251273"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251275"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251277"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251280"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251282"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251284"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251285"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251287"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251290"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251293"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251296"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251298"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251300"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251302"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251304"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251306"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251308"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251310"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251312"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251314"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251315"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251317"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251319"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251321"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251323"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251325"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251327"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251329"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251331"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251333"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251335"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251337"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251339"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251341"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251343"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251345"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251347"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251349"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251351"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251352"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251354"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251356"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251358"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251360"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251362"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251364"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251366"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251368"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251370"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251372"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251374"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251376"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251378"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251380"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251382"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251383"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251385"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251387"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251389"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251391"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251394"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251397"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251399"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251401"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251403"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251404"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251406"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251408"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251410"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251412"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251414"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251432"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251434"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251436"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251438"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251440"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251442"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251444"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251446"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251448"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251450"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251452"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251454"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251456"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251458"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251460"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251462"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251464"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251466"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251468"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251470"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251472"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251474"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251476"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251478"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251480"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251483"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251487"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251490"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251493"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251496"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251499"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251503"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251506"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251509"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251512"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251516"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251519"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251522"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251525"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251528"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251529"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251531"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251533"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251535"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251537"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251539"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251541"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251543"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251545"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251547"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251549"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251551"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251553"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251555"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251557"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251559"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251561"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251563"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251565"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251567"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251569"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251571"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251573"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251575"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251577"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251579"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251581"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251583"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251585"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251587"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251589"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251591"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251593"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251595"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251597"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251599"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251600"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251602"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251604"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251606"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251608"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251610"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251612"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251614"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251616"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251618"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251620"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251622"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251624"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251626"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251628"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251630"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251632"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251634"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251636"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251638"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251640"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251641"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251643"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251645"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251647"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251649"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251651"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251653"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251655"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251657"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251659"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251661"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251663"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251665"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251667"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251669"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251671"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251674"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251675"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251677"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251679"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251681"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251683"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251685"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251687"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251689"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251691"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251693"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251695"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251697"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251699"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251701"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251703"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251705"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251707"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251709"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251711"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251713"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251715"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251718"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251720"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251722"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251724"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251726"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251728"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251730"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251732"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251734"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251736"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251738"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251740"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251742"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251744"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251746"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251748"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251750"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251752"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251754"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251756"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251758"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251760"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251762"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251764"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251766"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251767"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251769"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251772"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251773"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251775"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251777"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251779"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251781"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251783"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251785"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251788"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251790"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251792"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251794"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251795"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251797"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251799"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251801"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251803"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251805"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251807"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251809"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251811"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251813"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251815"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251817"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251819"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251821"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251823"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251825"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251827"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251829"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251831"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251833"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251835"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251837"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251839"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251841"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251843"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251845"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251847"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251849"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251851"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251853"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251855"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251857"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251859"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251861"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251863"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251865"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251867"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251869"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251871"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251873"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251875"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251877"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251879"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251881"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251883"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251885"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251887"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251889"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251891"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251893"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251895"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251897"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251899"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251901"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251903"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251905"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251907"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251909"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251911"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251913"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251915"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251917"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251919"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251921"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251923"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251925"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251927"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251929"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251931"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251933"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251935"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251937"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251939"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251941"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251943"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251945"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251946"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251948"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251950"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251952"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251954"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251956"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251958"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251960"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251962"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251964"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251966"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251968"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251971"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251973"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251975"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251977"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251979"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251981"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251983"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251985"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251987"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251989"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251991"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251993"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251995"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251997"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.251999"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252001"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252003"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252004"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252006"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252008"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252010"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252012"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252014"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252016"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252018"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252020"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252022"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252035"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252037"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252039"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252041"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252043"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252045"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252047"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252049"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252051"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252053"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252055"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252057"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252059"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252060"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252062"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252064"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252066"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252068"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252071"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252072"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252074"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252076"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252078"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252080"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252082"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252084"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252086"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252088"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252090"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252093"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252095"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252097"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252098"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252100"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252102"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252104"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252106"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252108"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252110"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252112"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252114"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252116"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252118"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252120"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252122"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252124"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252126"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252128"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252130"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252132"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252134"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252136"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252138"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252140"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252145"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252147"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252149"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252151"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252153"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252155"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252157"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252172"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252174"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252176"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252178"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252180"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252182"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252184"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252186"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252189"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252191"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252193"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252195"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252197"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252199"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252201"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252203"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252205"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252207"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252209"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252211"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252213"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252215"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252217"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252219"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252221"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252222"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252224"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252227"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252229"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252231"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252233"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252235"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252237"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252239"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252241"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252243"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252245"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252247"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252249"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252251"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252253"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252255"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252257"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252259"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252261"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252263"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252265"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252267"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252269"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252271"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252273"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252275"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252277"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252279"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252281"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252283"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252285"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252287"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252289"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252291"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252293"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252295"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252297"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252299"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252301"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252303"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252305"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252307"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252309"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252311"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252313"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252315"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252317"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252319"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252321"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252323"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252325"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252327"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252329"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252331"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252333"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252335"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252337"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252339"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252341"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252343"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252345"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252347"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252349"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252351"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252353"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252355"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252357"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252359"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252361"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252363"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252365"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252367"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252369"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252371"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252373"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252375"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252377"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252379"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252381"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252383"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252385"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252387"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252389"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252391"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252394"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252397"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252399"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252401"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252402"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252405"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252406"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252408"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252410"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252412"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252414"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252416"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252418"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252420"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252422"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252424"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252426"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252428"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252430"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252432"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252434"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252436"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252438"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252440"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252442"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252444"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252446"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252448"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252450"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252452"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252454"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252456"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252458"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252460"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252462"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252464"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252466"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252468"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252470"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252472"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252474"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252476"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252478"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252480"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252482"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252484"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252486"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252488"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252490"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252492"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252494"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252496"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252498"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252500"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252502"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252504"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252506"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252508"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252510"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252512"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252514"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252516"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252518"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252520"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252522"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252524"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252526"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252528"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252530"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252532"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252534"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252536"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252538"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252540"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252542"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252544"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252546"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252547"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252549"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252552"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252553"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252555"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252558"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252560"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252562"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252564"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252567"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252571"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252574"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252577"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252580"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252583"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252586"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252590"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252593"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252596"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252600"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252603"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252606"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252608"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252610"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252612"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252614"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252616"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252618"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252620"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252622"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252623"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252626"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252628"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252630"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252632"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252634"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252636"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252638"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252640"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252642"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252644"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252646"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252648"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252650"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252652"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252654"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252656"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252658"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252660"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252662"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252663"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252665"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252667"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252669"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252671"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252673"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252675"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252677"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252679"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252681"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252683"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252685"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252687"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252689"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252691"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252693"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252695"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252697"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252699"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252701"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252703"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252705"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252707"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252709"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252711"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252713"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252715"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252716"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252718"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252720"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252722"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252724"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252726"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252728"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252730"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252732"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252734"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252736"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252738"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252740"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252742"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252744"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252746"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252748"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252750"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252752"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252754"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252756"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252758"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252760"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252762"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252764"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252766"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252768"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252770"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252772"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252774"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252776"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252779"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252781"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252782"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252784"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252786"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252788"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252790"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252792"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252794"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252796"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252798"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252800"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252802"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252804"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252806"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252808"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252810"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252812"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252814"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252816"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252818"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252820"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252822"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252824"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252826"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252828"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252830"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252832"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252834"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252836"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252838"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252840"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252842"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252844"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252846"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252848"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252850"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252852"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252854"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252856"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252858"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252860"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252862"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252864"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252866"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252868"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252870"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252871"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252873"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252876"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252877"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252879"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252881"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252883"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252885"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252901"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252903"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252905"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252907"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252909"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252910"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252912"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252914"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252916"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252918"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252920"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252922"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252924"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252926"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252928"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252930"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252932"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252934"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252936"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252938"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252940"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252942"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252944"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252946"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252948"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252950"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252952"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252954"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252956"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252958"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252960"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252962"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252964"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252966"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252968"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252970"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252972"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252974"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252976"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252977"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252980"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252982"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252983"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252985"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252988"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252990"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252992"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252994"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252996"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252997"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.252999"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253001"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253003"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253005"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253007"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253009"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253011"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253013"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253015"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253017"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253019"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253021"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253023"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253033"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253035"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253036"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253038"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253040"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253042"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253044"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253046"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253049"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253051"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253053"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253055"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253056"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253058"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253060"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253062"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253064"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253066"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253068"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253070"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253072"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253074"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253076"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253078"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253080"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253082"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253084"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253086"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253088"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253090"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253092"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253094"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253096"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253097"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253099"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253101"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253103"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253105"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253107"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253109"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253111"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253113"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253115"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253117"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253119"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253121"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253122"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253124"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253126"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253128"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253130"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253132"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253134"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253136"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253138"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253140"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253142"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253147"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253149"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253151"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253153"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253155"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253157"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253159"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253161"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253163"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253165"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253167"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253169"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253171"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253172"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253174"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253177"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253180"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253183"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253186"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253189"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253192"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253195"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253198"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253201"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253204"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253207"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253210"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253213"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253215"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253218"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253221"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253224"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253228"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253231"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253234"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253237"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253240"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253243"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253246"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253249"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253253"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253256"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253259"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253262"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253264"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253266"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253268"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253270"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253272"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253274"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253276"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253278"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253280"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253282"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253284"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253286"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253288"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253290"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253292"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253294"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253296"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253298"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253300"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253302"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253304"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253306"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253308"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253310"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253312"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253314"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253316"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253318"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253320"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253322"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253324"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253326"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253328"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253330"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253332"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253334"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253336"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253338"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253340"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253342"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253344"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253346"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253348"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253350"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253352"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253354"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253356"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253358"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253360"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253362"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253364"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253366"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253368"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253370"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253372"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253374"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253376"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253377"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253380"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253382"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253384"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253386"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253388"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253389"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253391"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253395"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253398"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253400"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253403"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253405"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253407"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253409"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253411"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253413"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253415"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253417"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253418"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253420"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253422"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253424"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253426"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253428"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253430"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253432"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253434"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253436"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253438"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253441"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253443"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253445"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253447"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253449"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253451"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253453"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253454"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253457"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253458"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253460"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253462"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253465"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253467"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253469"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253471"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253473"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253475"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253476"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253478"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253480"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253482"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253484"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253486"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253488"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253490"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253492"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253494"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253496"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253498"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253500"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253502"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253504"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253506"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253508"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253510"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253512"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253514"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253516"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253518"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253520"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253522"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253524"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253526"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253528"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253530"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253532"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253534"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253536"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253538"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253540"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253542"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253544"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253546"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253548"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253550"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253552"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253554"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253556"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253558"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253560"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253562"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253564"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253566"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253568"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253570"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253572"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253574"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253576"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253578"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253580"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253582"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253584"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253586"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253588"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253590"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253592"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253595"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253597"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253599"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253601"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253603"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253605"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253607"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253609"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253611"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253613"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253615"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253617"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253619"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253621"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253623"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253625"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253627"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253629"
    }
  },
  {
    "instruction": "Compare Adam, SGD, and RMSprop optimizers.",
    "input": "",
    "output": "SGD uses fixed learning rates. RMSprop adapts per-parameter based on squared gradients. Adam combines momentum and adaptive learning rates, making it robust across problems.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253631"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253633"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253635"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253636"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253657"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253660"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253664"
    }
  },
  {
    "instruction": "What is backpropagation?",
    "input": "",
    "output": "Backpropagation computes gradients by applying the chain rule through layers from output to input. It efficiently calculates partial derivatives for all parameters in neural networks.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253667"
    }
  },
  {
    "instruction": "Explain gradient descent optimization.",
    "input": "",
    "output": "Gradient descent iteratively moves parameters opposite to the gradient to minimize loss. Learning rate controls step size - too large causes divergence, too small causes slow convergence.",
    "domain": "ai_ml",
    "category": "training_optimization",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253671"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253675"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253679"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253683"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253686"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253688"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253690"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253692"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253694"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253696"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253698"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253700"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253702"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253704"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253706"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253708"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253710"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253712"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253713"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253715"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253717"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253719"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253721"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253723"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253725"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253727"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253729"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253732"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253734"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253736"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253738"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253739"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253741"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253743"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253745"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253747"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253749"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253751"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253753"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253755"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253757"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253759"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253761"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253763"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253765"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253767"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253769"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253771"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253772"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253775"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253777"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253779"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253780"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253782"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253784"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253787"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253789"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253791"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253793"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253795"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253797"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253799"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253801"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253802"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253804"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253806"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253808"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253810"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253812"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253814"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253816"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253818"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253820"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253822"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253824"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253826"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253828"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253830"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253832"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253834"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253836"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253838"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253840"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253842"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253843"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253845"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253847"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253849"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253851"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253853"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253855"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253857"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253859"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253861"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253863"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253865"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253867"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253869"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253871"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253873"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253875"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253877"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253879"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253881"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253883"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253885"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253887"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253889"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253891"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253893"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253895"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253897"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253899"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253901"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253903"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253905"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253907"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253909"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253911"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253913"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253915"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253917"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253918"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253920"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253922"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253924"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253926"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253928"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253931"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253933"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253934"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253936"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253938"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253940"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253942"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253944"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253946"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253948"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253950"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253952"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253954"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253956"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253958"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253959"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253961"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253963"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253965"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253967"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253969"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253971"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253973"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253975"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253977"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253979"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253981"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253983"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253985"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253987"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253989"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253991"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253993"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253994"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253996"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.253999"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254001"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254003"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254005"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254006"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254008"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254010"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254012"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254014"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254016"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254018"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254020"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254022"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254035"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254037"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254039"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254041"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254043"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254045"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254047"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254049"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254051"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254053"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254055"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254057"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254059"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254061"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254062"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254064"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254066"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254068"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254070"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254072"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254074"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254076"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254078"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254080"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254082"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254084"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254086"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254088"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254090"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254092"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254094"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254096"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254098"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254100"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254102"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254104"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254106"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254108"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254110"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254112"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254114"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254116"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254118"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254120"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254122"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254124"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254126"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254128"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254130"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254132"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254134"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254136"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254138"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254140"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254145"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254147"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254149"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254151"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254153"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254155"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254157"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254159"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254161"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254163"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254165"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254167"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254168"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254170"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254172"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254174"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254176"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254178"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254180"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254182"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254184"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254186"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254188"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254190"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254192"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254194"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254196"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254198"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254200"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254203"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254205"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254207"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254209"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254211"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254213"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254215"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254217"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254219"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254221"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254223"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254225"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254227"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254228"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254230"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254232"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254234"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254236"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254238"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254240"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254242"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254244"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254246"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254248"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254250"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254252"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254254"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254256"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254258"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254260"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254262"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254264"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254266"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254268"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254270"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254272"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254274"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254276"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254277"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254279"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254281"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254283"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254285"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254287"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254289"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254291"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254294"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254297"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254299"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254301"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254303"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254305"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254307"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254309"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254311"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254313"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254315"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254317"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254320"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254322"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254324"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254325"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254327"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254329"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254331"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254333"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254335"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254337"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254339"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254341"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254343"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254345"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254347"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254349"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254351"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254353"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254355"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254357"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254359"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254361"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254363"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254364"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254367"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254369"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254371"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254373"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254375"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254595"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254598"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254600"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254602"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254604"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254606"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254608"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254610"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254613"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254615"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254617"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254619"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254621"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254623"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254625"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254627"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254629"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254631"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254633"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254635"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254637"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254639"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254641"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254643"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254645"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254647"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254649"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254651"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254653"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254655"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254657"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254659"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254661"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254663"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254665"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254667"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254669"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254671"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254673"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254675"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254677"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254679"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254681"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254683"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254685"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254687"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254689"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254691"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254693"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254695"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254697"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254699"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254701"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254703"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254705"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254707"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254709"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254711"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254713"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254715"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254717"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254719"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254721"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254723"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254725"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254729"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254732"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254735"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254738"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254741"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254744"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254747"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254750"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254753"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254756"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254759"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254763"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254766"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254770"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254773"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254776"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254779"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254782"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254784"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254786"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254788"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254791"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254793"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254795"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254797"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254799"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254801"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254803"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254805"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254807"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254809"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254811"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254813"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254815"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254817"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254819"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254821"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254823"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254825"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254827"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254829"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254830"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254832"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254834"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254836"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254838"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254840"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254842"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254844"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254846"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254848"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254850"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254852"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254854"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254856"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254858"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254860"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254862"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254864"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254866"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254868"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254870"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254872"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254874"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254876"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254878"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254880"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254882"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254884"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254886"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254888"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254890"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254892"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254894"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254896"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254898"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254900"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254902"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254904"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254906"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254908"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254910"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254912"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254914"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254916"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254918"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254920"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254922"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254924"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254926"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254927"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254929"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254931"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254933"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254935"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254937"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254939"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254941"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254943"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254945"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254947"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254949"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254952"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254954"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254956"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254958"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254960"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254962"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254964"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254966"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254968"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254970"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254971"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254973"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254975"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254977"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254979"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254981"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254983"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254985"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254987"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254989"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254991"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254993"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254995"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254997"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.254999"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255001"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255003"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255005"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255007"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255009"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255011"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255013"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255015"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255017"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255019"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255021"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255023"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255033"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255035"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255037"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255039"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255041"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255043"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255045"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255047"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255049"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255051"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255053"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255055"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255057"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255059"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255061"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255063"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255065"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255067"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255069"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255071"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255073"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255075"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255077"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255079"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255081"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255083"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255085"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255087"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255089"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255091"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255093"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255095"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255097"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255099"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255101"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255103"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255105"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255107"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255109"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255111"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255113"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255115"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255117"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255119"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255121"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255123"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255125"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255127"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255128"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255131"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255132"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255134"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255136"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255138"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255140"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255146"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255148"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255150"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255152"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255154"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255157"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255159"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255161"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255163"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255165"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255167"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255169"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255171"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255173"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255175"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255177"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255179"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255181"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255183"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255185"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255187"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255189"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255191"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255193"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255195"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255197"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255199"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255201"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255203"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255205"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255207"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255209"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255211"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255213"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255215"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255218"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255220"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255222"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255224"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255226"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255228"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255230"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255232"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255234"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255236"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255238"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255240"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255242"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255244"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255246"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255248"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255249"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255251"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255253"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255255"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255257"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255259"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255261"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255263"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255265"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255267"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255269"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255271"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255273"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255275"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255277"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255279"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255281"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255283"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255285"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255287"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255289"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255291"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255293"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255295"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255297"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255299"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255301"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255303"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255305"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255307"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255309"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255311"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255313"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255315"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255317"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255319"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255321"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255323"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255324"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255326"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255343"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255345"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255347"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255349"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255350"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255352"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255354"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255356"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255358"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255360"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255362"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255364"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255366"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255369"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255371"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255373"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255375"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255377"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255379"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255381"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255383"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255385"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255387"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255389"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255391"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255393"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255396"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255398"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255400"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255402"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255404"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255406"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255408"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255410"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255412"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255414"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255417"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255419"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255421"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255423"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255425"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255427"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255429"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255431"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255433"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255435"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255437"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255439"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255441"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255443"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255445"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255447"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255448"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255450"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255452"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255454"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255456"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255458"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255460"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255462"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255464"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255466"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255468"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255470"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255472"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255474"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255476"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255478"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255480"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255482"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255484"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255485"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255488"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255489"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255491"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255493"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255495"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255497"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255499"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255501"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255503"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255505"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255507"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255509"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255511"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255513"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255515"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255517"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255519"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255521"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255523"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255525"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255527"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255529"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255530"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255532"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255534"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255536"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255538"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255540"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255542"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255544"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255546"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255548"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255550"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255552"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255554"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255556"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255558"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255560"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255562"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255564"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255566"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255568"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255570"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255571"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255573"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255575"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255578"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255580"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255582"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255584"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255586"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255588"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255589"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255591"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255593"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255596"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255598"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255600"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255602"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255604"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255606"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255608"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255610"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255612"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255614"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255616"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255618"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255619"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255622"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255623"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255625"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255627"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255629"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255631"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255633"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255635"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255637"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255639"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255641"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255643"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255645"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255647"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255649"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255651"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255653"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255655"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255657"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255659"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255661"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255663"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255665"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255667"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255669"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255671"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255674"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255675"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255677"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255680"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255682"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255684"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255686"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255688"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255690"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255691"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255693"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255695"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255697"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255699"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255701"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255703"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255705"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255707"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255709"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255711"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255713"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255715"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255717"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255719"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255720"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255722"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255724"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255726"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255728"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255730"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255733"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255735"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255737"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255739"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255741"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255743"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255745"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255747"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255749"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255751"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255753"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255755"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255757"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255759"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255761"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255763"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255765"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255767"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255769"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255771"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255773"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255775"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255777"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255779"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255781"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255783"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255785"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255787"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255789"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255791"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255793"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255795"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255797"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255799"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255801"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255803"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255805"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255807"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255809"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255811"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255813"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255815"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255818"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255821"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255824"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255827"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255830"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255833"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255837"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255840"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255843"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255847"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255851"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255855"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255859"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255862"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255864"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255866"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255868"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255870"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255872"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255874"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255876"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255878"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255880"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255882"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255884"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255886"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255888"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255890"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255892"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255894"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255896"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255898"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255900"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255902"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255904"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255906"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255908"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255910"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255912"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255914"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255916"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255918"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255920"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255922"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255924"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255926"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255928"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255930"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255932"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255934"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255936"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255938"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255940"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255942"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255944"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255946"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255948"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255950"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255952"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255954"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255956"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255958"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255960"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255962"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255964"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255966"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255968"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255970"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255972"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255974"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255976"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255978"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255980"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255982"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255984"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255986"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255988"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255990"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255992"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255994"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255996"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.255998"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256000"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256001"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256003"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256006"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256008"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256010"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256012"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256014"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256016"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256018"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256020"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256022"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256031"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256033"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256035"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256037"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256039"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256041"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256043"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256045"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256047"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256048"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256051"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256053"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256055"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256056"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256058"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256060"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256062"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256064"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256080"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256082"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256084"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256086"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256088"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256090"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256092"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256093"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256095"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256097"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256099"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256101"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256103"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256105"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256107"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256109"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256111"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256113"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256115"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256117"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256119"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256121"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256123"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256125"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256127"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256129"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256131"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256133"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256135"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256137"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256139"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256141"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256146"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256148"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256150"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256152"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256154"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256156"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256158"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256160"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256162"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256164"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256165"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256167"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256169"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256171"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256173"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256175"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256177"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256179"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256181"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256183"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256185"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256187"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256189"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256191"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256193"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256195"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256197"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256199"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256201"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256203"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256205"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256207"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256208"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256210"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256218"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256221"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256223"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256225"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256227"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256229"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256231"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256233"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256235"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256237"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256239"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256241"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256243"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256245"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256247"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256249"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256251"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256253"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256255"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256258"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256262"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256265"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256268"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256272"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256275"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256278"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256282"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256285"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256288"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256290"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256292"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256294"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256296"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256298"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256301"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256303"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256305"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256307"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256309"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256311"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256313"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256314"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256316"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256319"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256321"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256323"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256325"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256327"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256329"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256330"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256333"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256335"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256336"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256338"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256340"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256342"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256344"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256346"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256348"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256350"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256352"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256354"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256356"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256358"
    }
  },
  {
    "instruction": "Explain precision, recall, and F1-score.",
    "input": "",
    "output": "Precision = TP/(TP+FP) measures false positive rate. Recall = TP/(TP+FN) measures false negative rate. F1 = 2*(Precision*Recall)/(Precision+Recall) balances both.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256360"
    }
  },
  {
    "instruction": "What is the confusion matrix?",
    "input": "",
    "output": "The confusion matrix has True Positives, True Negatives, False Positives, and False Negatives. It enables calculating precision, recall, specificity, and other classification metrics.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256362"
    }
  },
  {
    "instruction": "When should you use ROC-AUC vs Accuracy?",
    "input": "",
    "output": "Use Accuracy for balanced datasets. ROC-AUC is better for imbalanced datasets as it's threshold-independent and shows performance across different trade-offs.",
    "domain": "ai_ml",
    "category": "model_evaluation",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256364"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256368"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256370"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256372"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256374"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256376"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256378"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256380"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256382"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256384"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256386"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256388"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256392"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256395"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256398"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256400"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256402"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256403"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256405"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256407"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256409"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256411"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256413"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256415"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256417"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256419"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256421"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256423"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256425"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256427"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256429"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256431"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256433"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256435"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256437"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256439"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256441"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256443"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256445"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256447"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256449"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256451"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256453"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256455"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256457"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256460"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256461"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256463"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256465"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256467"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256469"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256471"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256473"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256475"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256477"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256479"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256481"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256483"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256485"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256487"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256490"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256493"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256836"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256840"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256842"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256844"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256846"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256848"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256850"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256852"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256857"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256859"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256861"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256863"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256865"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256867"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256869"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256871"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256873"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256875"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256877"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256879"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256881"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256883"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256885"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256887"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256889"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256891"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256893"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256895"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256897"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256899"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256902"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256908"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256912"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256915"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256919"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256922"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256925"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256928"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256932"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256938"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256941"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256944"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256946"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256948"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256950"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256952"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256954"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256956"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256958"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256960"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256962"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256964"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256966"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256968"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256970"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256972"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256974"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256976"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256978"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256980"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256982"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256984"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256986"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256993"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256995"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256997"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.256999"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257001"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257003"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257005"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257007"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257011"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257013"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257015"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257017"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257019"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257020"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257022"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257038"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257040"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257042"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257044"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257046"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257048"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257050"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257054"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257056"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257058"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257060"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257062"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257064"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257066"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257068"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257070"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257072"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257076"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257078"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257080"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257082"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257084"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257086"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257088"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257090"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257094"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257095"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257097"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257100"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257102"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257104"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257106"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257110"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257112"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257113"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257115"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257117"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257119"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257121"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257123"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257125"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257127"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257129"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257131"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257133"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257135"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257137"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257139"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257141"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257149"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257151"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257153"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257155"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257157"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257159"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257161"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257163"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257169"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257171"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257173"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257175"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257177"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257179"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257181"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257182"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257184"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257186"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257188"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257190"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257192"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257194"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257196"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257198"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257200"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257202"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257204"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257206"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257208"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257231"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257233"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257237"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257239"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257241"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257244"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257246"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257248"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257250"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257252"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257254"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257258"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257260"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257262"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257264"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257266"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257267"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257269"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257271"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257273"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257275"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257277"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257279"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257281"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257283"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257285"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257287"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257289"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257291"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257293"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257295"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257299"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257300"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257303"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257306"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257308"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257310"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257312"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257314"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257316"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257318"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257320"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257322"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257326"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257328"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257330"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257332"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257334"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257336"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257338"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257340"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257342"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257344"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257346"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257348"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257349"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257355"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257356"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257358"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257360"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257362"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257364"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257366"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257368"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257370"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257372"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257376"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257378"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257380"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257382"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257384"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257386"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257388"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257390"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257391"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257405"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257407"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257409"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257411"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257413"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257414"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257418"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257420"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257422"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257424"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257426"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257428"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257430"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257432"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257434"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257436"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257438"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257440"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257442"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257444"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257446"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257448"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257450"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257454"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257456"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257458"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257460"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257462"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257464"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257466"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257467"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257469"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257475"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257477"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257479"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257481"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257483"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257485"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257487"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257489"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257491"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257493"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257494"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257496"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257498"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257500"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257502"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257504"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257506"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257508"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257510"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257512"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257514"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257516"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257520"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257522"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257524"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257526"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257530"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257532"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257534"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257536"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257538"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257542"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257544"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257546"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257547"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257549"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257551"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257553"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257555"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257557"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257559"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257561"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257563"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257565"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257567"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257569"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257571"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257573"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257575"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257577"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257579"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257582"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257584"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257586"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257590"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257592"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257594"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257596"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257598"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257600"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257602"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257604"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257606"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257610"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257612"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257614"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257616"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257617"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257619"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257621"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257623"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257625"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257627"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257629"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257631"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257633"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257637"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257639"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257641"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257643"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257645"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257647"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257649"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257651"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257653"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257655"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257659"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257661"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257662"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257664"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257666"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257668"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257670"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257672"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257674"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257679"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257681"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257683"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257685"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257687"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257689"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257691"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257695"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257697"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257699"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257701"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257703"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257705"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257707"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257709"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257711"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257713"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257715"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257717"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257718"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257720"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257722"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257724"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257728"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257730"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257732"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257734"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257736"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257738"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257740"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257742"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257744"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257748"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257751"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257753"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257755"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257757"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257759"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257761"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257763"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257765"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257767"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257769"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257771"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257773"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257775"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257777"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257779"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257781"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257783"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257785"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257787"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257789"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257791"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257794"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257796"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257798"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257800"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257804"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257806"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257808"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257810"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257812"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257814"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257817"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257819"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257821"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257823"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257825"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257827"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257829"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257831"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257833"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257835"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257837"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257839"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257841"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257843"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257845"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257847"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257849"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257851"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257853"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257856"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257858"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257860"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257864"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257866"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257868"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257870"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257872"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257874"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257876"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257878"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257880"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257882"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257886"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257888"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257892"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257894"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257896"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257898"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257900"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257902"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257904"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257906"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257908"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257910"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257912"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257915"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257917"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257919"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257921"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257923"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257925"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257927"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257929"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257931"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257935"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257937"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257939"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257940"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257942"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257944"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257946"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257948"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257950"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257952"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257956"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257958"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257960"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257962"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257964"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257966"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257968"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257973"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257975"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257977"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257979"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257981"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257984"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257987"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257990"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257994"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257996"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.257999"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258003"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258006"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258035"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258038"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258042"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258044"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258046"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258048"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258050"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258052"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258054"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258056"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258058"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258060"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258066"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258068"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258070"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258072"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258074"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258076"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258079"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258081"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258083"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258085"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258086"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258088"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258090"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258093"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258095"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258096"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258098"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258100"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258102"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258104"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258106"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258110"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258112"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258114"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258116"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258120"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258122"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258124"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258126"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258128"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258130"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258133"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258135"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258137"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258139"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258141"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258146"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258148"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258150"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258152"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258154"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258156"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258158"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258160"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258162"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258164"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258166"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258168"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258170"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258172"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258174"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258178"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258180"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258183"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258185"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258187"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258189"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258191"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258193"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258195"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258197"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258199"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258201"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258205"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258207"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258209"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258211"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258213"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258215"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258217"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258219"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258221"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258223"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258225"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258227"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258229"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258231"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258234"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258236"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258238"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258240"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258242"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258244"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258246"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258248"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258252"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258254"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258256"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258258"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258260"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258262"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258264"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258266"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258268"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258270"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258274"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258276"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258278"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258280"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258282"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258284"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258286"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258289"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258291"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258293"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258295"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258297"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258299"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258301"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258303"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258305"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258307"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258309"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258311"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258313"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258315"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258317"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258321"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258323"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258325"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258327"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258329"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258331"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258332"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258334"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258336"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258339"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258346"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258348"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258350"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258352"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258354"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258356"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258358"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258360"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258362"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258364"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258365"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258367"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258369"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258371"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258373"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258375"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258377"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258379"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258381"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258383"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258385"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258389"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258391"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258394"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258397"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258399"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258403"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258405"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258407"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258409"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258411"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258413"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258417"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258419"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258421"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258423"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258425"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258427"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258429"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258430"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258432"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258434"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258436"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258438"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258440"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258442"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258444"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258446"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258448"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258450"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258452"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258454"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258459"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258462"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258464"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258466"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258468"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258470"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258472"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258474"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258476"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258478"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258480"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258482"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258486"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258488"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258490"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258492"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258494"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258496"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258498"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258500"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258502"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258504"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258506"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258508"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258510"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258513"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258515"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258517"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258519"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258521"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258523"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258525"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258527"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258531"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258533"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258535"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258537"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258539"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258541"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258543"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258545"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258547"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258549"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258550"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258554"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258556"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258558"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258560"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258562"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258564"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258568"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258570"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258572"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258574"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258576"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258578"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258580"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258582"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258584"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258586"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258588"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258590"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258592"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258594"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258596"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258600"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258602"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258604"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258606"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258607"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258609"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258612"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258614"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258615"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258617"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258619"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258625"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258627"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258629"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258631"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258633"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258635"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258637"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258639"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258641"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258643"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258645"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258647"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258649"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258651"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258653"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258655"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258657"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258659"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258661"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258663"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258668"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258670"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258672"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258674"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258676"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258678"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258681"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258683"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258685"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258687"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258689"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258693"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258695"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258697"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258699"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258701"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258703"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258705"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258706"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258708"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258710"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258712"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258714"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258716"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258718"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258720"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258722"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258724"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258726"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258728"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258730"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258733"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258737"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258739"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258741"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258743"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258745"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258747"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258749"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258751"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258752"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258754"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258756"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258768"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258770"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258772"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258774"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258776"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258778"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258780"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258782"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258784"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258786"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258788"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258790"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258792"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258795"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258797"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258799"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258801"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258803"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258805"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258807"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258822"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258826"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258828"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258830"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258832"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258834"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258836"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258838"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258840"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258842"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258844"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258846"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258850"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258852"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258854"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258856"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258858"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258860"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258862"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258865"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258867"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258869"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258871"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258873"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258875"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258877"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258879"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258881"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258883"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258885"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258887"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258889"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258891"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258895"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258897"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258899"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258901"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258903"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258905"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258907"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258909"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258910"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258913"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258915"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258919"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258922"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258924"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258926"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258928"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258930"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258932"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258934"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258936"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258938"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258940"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258942"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258944"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258946"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258948"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258950"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258952"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258954"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258955"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258957"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258961"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258963"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258965"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258967"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258969"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258971"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258975"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258977"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258979"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258981"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258983"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258984"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258989"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258991"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258993"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258995"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258997"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.258999"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259001"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259003"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259005"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259007"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259009"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259011"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259013"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259015"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259017"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259019"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259021"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259023"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259035"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259039"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259043"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259045"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259047"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259048"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259050"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259052"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259054"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259056"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259058"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259060"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259062"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259064"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259070"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259073"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259076"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259079"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259083"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259086"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259089"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259092"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259096"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259099"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259102"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259105"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259108"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259113"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259115"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259116"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259119"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259121"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259123"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259125"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259128"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259130"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259132"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259134"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259136"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259138"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259140"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259142"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259147"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259149"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259151"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259154"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259157"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259159"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259161"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259163"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259165"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259167"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259169"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259173"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259175"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259177"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259179"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259181"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259183"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259185"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259187"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259189"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259191"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259193"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259195"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259197"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259201"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259203"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259205"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259207"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259209"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259211"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259213"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259215"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259217"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259219"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259221"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259223"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259229"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259231"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259233"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259235"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259237"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259239"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259241"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259243"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259245"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259247"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259249"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259251"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259253"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259255"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259257"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259259"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259261"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259263"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259265"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259269"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259270"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259272"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259274"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259276"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259278"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259282"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259284"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259286"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259288"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259290"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259292"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259296"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259298"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259300"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259302"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259304"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259306"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259308"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259310"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259312"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259313"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259315"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259317"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259319"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259321"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259323"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259325"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259327"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259329"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259331"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259333"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259340"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259342"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259344"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259346"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259348"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259350"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259352"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259354"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259356"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259358"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259360"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259362"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259366"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259368"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259370"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259372"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259374"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259376"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259378"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259380"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259382"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259384"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259386"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259388"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259389"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259392"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259397"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259399"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259401"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259403"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259405"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259407"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259411"
    }
  },
  {
    "instruction": "Explain adversarial examples.",
    "input": "",
    "output": "Adversarial examples are inputs designed to fool ML models. Small perturbations to images can cause misclassification. This highlights vulnerability to input manipulations.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259413"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259415"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259417"
    }
  },
  {
    "instruction": "What is AI alignment?",
    "input": "",
    "output": "AI alignment means ensuring AI systems' objectives match human values and intentions. Misaligned AI could optimize for wrong goals, causing harmful outcomes despite technical sophistication.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259419"
    }
  },
  {
    "instruction": "What are potential risks of large language models?",
    "input": "",
    "output": "Risks include bias amplification, misinformation generation, privacy violations, and environmental impact. Mitigation requires diverse training data, careful fine-tuning, and honest disclaimers.",
    "domain": "ai_ml",
    "category": "ai_safety",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259423"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259426"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259428"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259430"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259432"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259435"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259436"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259440"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259442"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259444"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259446"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259448"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259450"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259452"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259456"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259458"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259460"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259462"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259464"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259466"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259468"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259470"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259472"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259474"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259476"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259478"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259480"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259483"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259485"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259487"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259489"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259491"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259493"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259495"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259497"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259499"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259501"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259503"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259505"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259511"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259513"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259515"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259517"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259518"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259520"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259522"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259524"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259526"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259528"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259530"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259532"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259534"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259536"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259538"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259540"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259542"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259544"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259546"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259550"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259552"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259554"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259556"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259558"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259560"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259562"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259565"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259567"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259569"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259571"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259573"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259575"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259579"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259581"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259583"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259585"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259587"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259589"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259591"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259593"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259595"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259597"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259599"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259601"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259603"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259605"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259607"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259609"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259611"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259613"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259615"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259634"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259638"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259640"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259642"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259644"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259646"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259648"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259650"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259652"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259654"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259656"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259658"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259660"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259665"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259667"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259669"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259671"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259673"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259674"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259676"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259678"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259680"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259682"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259684"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259686"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259688"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259692"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259694"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259696"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259698"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259700"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259702"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259705"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259707"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259709"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259711"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259713"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259715"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259717"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259719"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259721"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259723"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259725"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259727"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259729"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259733"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259735"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259737"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259739"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259741"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259743"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259747"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259749"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259751"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259753"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259755"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259757"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259759"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259761"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259763"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259765"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259766"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259768"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259771"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259774"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259776"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259778"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259780"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259782"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259784"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259786"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259788"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259790"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259792"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259794"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259796"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259798"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259804"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259806"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259808"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259810"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259812"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259814"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259816"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259818"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259820"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259822"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259824"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259826"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259828"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259829"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259831"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259833"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259835"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259837"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259841"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259843"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259845"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259847"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259849"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259851"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259853"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259855"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259858"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259860"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259862"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259864"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259866"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259870"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259872"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259874"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259876"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259878"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259880"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259881"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259883"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259885"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259887"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259889"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259891"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259893"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259895"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259897"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259899"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259901"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259903"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259905"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259908"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259912"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259914"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259916"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259918"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259920"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259922"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259924"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259926"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259928"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259930"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259932"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259934"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259937"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259939"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259941"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259943"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259945"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259947"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259949"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259951"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259953"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259955"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259957"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259959"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259961"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259965"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259966"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259968"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259970"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259972"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259974"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259979"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259981"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259983"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259985"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259987"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259989"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259991"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259993"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259995"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259997"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.259999"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260001"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260003"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260007"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260009"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260011"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260013"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260014"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260016"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260018"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260022"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260032"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260034"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260036"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260038"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260040"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260042"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260044"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260046"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260048"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260050"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260052"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260056"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260057"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260059"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260061"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260064"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260066"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260068"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260069"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260071"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260073"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260075"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260077"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260079"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260083"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260087"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260089"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260091"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260093"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260095"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260097"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260099"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260101"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260103"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260105"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260107"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260109"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260111"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260113"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260115"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260117"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260119"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260122"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260124"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260126"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260128"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260130"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260132"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260134"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260136"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260140"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260142"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260147"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260152"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260155"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260158"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260173"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260176"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260180"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260183"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260186"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260188"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260190"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260192"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260194"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260196"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260198"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260200"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260202"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260204"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260206"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260208"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260210"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260212"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260216"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260220"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260222"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260224"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260225"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260228"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260230"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260231"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260233"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260235"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260237"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260239"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260241"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260243"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260247"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260249"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260251"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260253"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260255"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260257"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260259"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260261"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260263"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260265"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260267"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260268"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260270"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260274"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260276"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260278"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260280"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260282"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260286"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260288"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260290"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260292"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260294"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260296"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260298"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260300"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260302"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260304"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260306"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260308"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260310"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260312"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260315"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260317"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260319"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260321"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260323"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260325"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260328"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260333"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260335"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260337"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260339"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260341"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260343"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260344"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260347"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260348"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260350"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260352"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260356"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260358"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260360"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260362"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260364"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260366"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260368"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260370"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260372"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260374"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260376"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260378"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260380"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260382"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260387"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260389"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260391"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260394"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260397"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260399"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260401"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260403"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260405"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260407"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260408"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260410"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260412"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260414"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260416"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260418"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260420"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260424"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260439"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260441"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260443"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260445"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260447"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260449"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260451"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260455"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260457"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260459"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260461"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260463"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260465"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260469"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260471"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260473"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260475"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260477"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260479"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260481"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260482"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260484"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260486"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260488"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260490"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260492"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260494"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260496"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260498"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260500"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260502"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260506"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260508"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260511"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260513"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260515"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260517"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260519"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260521"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260523"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260525"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260527"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260529"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260531"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260533"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260537"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260538"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260541"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260542"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260544"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260547"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260549"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260551"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260553"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260555"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260557"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260559"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260561"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260563"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260566"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260568"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260570"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260572"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260576"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260578"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260580"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260582"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260584"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260586"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260588"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260590"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260592"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260594"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260596"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260598"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260600"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260602"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260606"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260608"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260610"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260612"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260614"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260616"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260618"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260622"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260624"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260626"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260627"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260629"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260631"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260633"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260635"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260637"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260639"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260641"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260645"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260647"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260649"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260651"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260653"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260655"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260657"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260659"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260661"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260663"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260665"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260666"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260668"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260671"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260677"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260679"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260681"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260683"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260685"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260687"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260689"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260691"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260693"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260695"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260697"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260699"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260701"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260703"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260705"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260707"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260709"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260712"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260714"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260717"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260718"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260720"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260722"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260724"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260726"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260728"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260733"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260734"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260736"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260738"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260740"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260742"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260746"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260748"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260750"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260752"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260754"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260756"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260758"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260760"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260762"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260764"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260766"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260768"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260770"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260772"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260774"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260776"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260778"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260781"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260783"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260785"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260789"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260791"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260793"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260795"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260797"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260799"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260801"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260803"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260805"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260807"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260809"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260811"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260815"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260816"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260819"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260820"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260822"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260824"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260826"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260828"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260830"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260832"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260834"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260836"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260838"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260842"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260844"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260846"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260848"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260851"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260853"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260855"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260857"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260859"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260861"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260863"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260865"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260867"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260869"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260871"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260873"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260875"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260877"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260879"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260883"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260885"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260887"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260889"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260891"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260892"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260896"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260898"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260900"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260902"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260904"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260906"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260908"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260910"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260912"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260914"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260916"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260920"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260922"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260924"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260926"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260927"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260929"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260931"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260933"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260935"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260937"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260939"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260941"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260943"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260945"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260947"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260953"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260955"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260957"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260959"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260961"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260963"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260965"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260967"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260969"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260971"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260973"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260975"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260977"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260979"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260981"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260983"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260988"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260990"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260992"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260995"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260997"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.260999"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261001"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261003"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261004"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261006"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261010"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261012"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261014"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261016"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261018"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261022"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261031"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261033"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261035"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261037"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261039"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261041"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261043"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261045"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261047"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261049"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261051"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261053"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261055"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261057"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261059"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261061"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261065"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261067"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261069"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261073"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261075"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261077"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261079"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261081"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261083"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261085"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261087"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261089"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261091"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261092"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261095"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261100"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261102"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261104"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261106"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261108"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261110"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261112"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261114"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261116"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261118"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261120"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261122"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261124"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261127"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261129"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261131"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261133"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261137"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261139"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261141"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261146"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261148"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261150"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261152"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261154"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261156"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261158"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261160"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261162"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261164"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261166"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261168"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261172"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261174"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261176"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261178"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261180"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261182"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261184"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261187"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261189"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261191"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261193"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261195"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261197"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261199"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261201"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261203"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261205"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261210"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261225"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261229"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261233"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261236"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261239"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261242"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261246"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261249"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261252"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261256"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261259"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261263"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261266"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261268"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261273"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261277"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261279"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261281"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261283"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261285"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261287"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261288"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261290"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261292"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261295"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261297"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261299"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261301"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261302"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261304"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261308"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261310"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261312"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261314"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261316"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261318"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261320"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261322"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261324"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261326"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261331"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261333"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261335"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261337"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261339"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261341"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261345"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261347"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261350"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261352"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261354"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261356"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261358"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261360"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261362"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261364"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261366"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261368"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261370"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261372"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261374"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261376"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261380"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261382"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261384"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261388"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261390"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261392"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261395"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261397"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261399"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261402"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261403"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261405"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261407"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261409"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261411"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261413"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261417"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261419"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261421"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261423"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261425"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261427"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261429"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261431"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261433"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261435"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261437"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261439"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261441"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261445"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261447"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261449"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261452"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261454"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261456"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261458"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261460"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261462"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261464"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261466"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261468"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261470"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261472"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261474"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261476"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261478"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261480"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261482"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261486"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261488"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261490"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261492"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261494"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261495"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261497"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261501"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261503"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261505"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261507"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261509"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261511"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261513"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261515"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261517"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261520"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261522"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261524"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261526"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261528"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261530"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261532"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261534"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261536"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261538"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261540"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261542"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261544"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261546"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261548"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261550"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261562"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261564"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261566"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261568"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261570"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261572"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261574"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261576"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261578"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261580"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261582"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261584"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261586"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261588"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261590"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261593"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261595"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261597"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261599"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261601"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261603"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261605"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261607"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261609"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261611"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261615"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261617"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261619"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261621"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261623"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261625"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261630"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261632"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261634"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261636"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261638"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261640"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261642"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261644"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261646"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261648"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261650"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261652"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261654"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261656"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261658"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261660"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261663"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261665"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261667"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261669"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261673"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261675"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261677"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261679"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261681"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261683"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261685"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261687"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261689"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261691"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261693"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261695"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261699"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261700"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261702"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261704"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261706"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261708"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261710"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261712"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261714"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261716"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261718"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261720"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261722"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261724"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261728"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261730"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261733"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261735"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261738"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261740"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261742"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261744"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261746"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261748"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261750"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261751"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261754"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261755"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261757"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261759"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261761"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261763"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261767"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261769"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261771"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261773"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261775"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261777"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261779"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261783"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261784"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261786"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261788"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261791"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261793"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261795"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261797"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261799"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261802"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261804"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261806"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261808"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261810"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261812"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261814"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261816"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261818"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261820"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261822"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261824"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261826"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261828"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261830"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261832"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261837"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261839"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261841"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261843"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261845"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261847"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261849"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261851"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261853"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261855"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261857"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261859"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261861"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261863"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261865"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261869"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261871"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261873"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261875"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261877"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261879"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261881"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261883"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261885"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261887"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261889"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261893"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261895"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261897"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261898"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261900"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261902"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261906"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261908"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261910"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261912"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261914"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261916"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261918"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261920"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261922"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261924"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261926"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261928"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261930"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261932"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261934"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261938"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261940"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261942"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261944"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261946"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261951"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261953"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261955"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261957"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261959"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261961"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261963"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261965"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261967"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261969"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261971"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261973"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261976"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261978"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261980"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261982"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261984"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261986"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261989"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261991"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261993"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261995"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261997"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.261999"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262001"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262005"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262007"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262010"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262013"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262047"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262050"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262054"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262057"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262061"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262064"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262067"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262069"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262071"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262073"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262075"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262077"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262079"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262081"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262083"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262087"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262089"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262091"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262094"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262096"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262097"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262101"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262103"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262105"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262107"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262109"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262111"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262113"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262115"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262117"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262121"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262123"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262125"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262127"
    }
  },
  {
    "instruction": "What is algorithmic bias and how can we address it?",
    "input": "",
    "output": "Algorithmic bias occurs when training data reflects historical discrimination. Solutions include diverse datasets, bias auditing, fairness metrics, and accountability frameworks.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262129"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262131"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262133"
    }
  },
  {
    "instruction": "What is explainability in AI?",
    "input": "",
    "output": "Explainability means understanding why models make decisions. Black-box models are hard to trust. Techniques like SHAP, LIME, and attention visualization improve interpretability.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262135"
    }
  },
  {
    "instruction": "Discuss privacy concerns in machine learning.",
    "input": "",
    "output": "Privacy risks include training data memorization, model inversion attacks, and member inference attacks. Mitigations: differential privacy, federated learning, data anonymization.",
    "domain": "ai_ml",
    "category": "ethics_in_ai",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262137"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262140"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262147"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262149"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262151"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262153"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262155"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262157"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262159"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262165"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262167"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262169"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262171"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262173"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262175"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262177"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262179"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262181"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262183"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262185"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262187"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262189"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262191"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262195"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262197"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262199"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262201"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262203"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262204"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262206"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262208"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262210"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262212"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262214"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262217"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262221"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262223"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262225"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262227"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262229"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262233"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262235"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262237"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262238"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262240"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262242"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262244"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262246"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262248"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262250"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262252"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262254"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262256"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262258"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262260"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262264"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262266"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262268"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262270"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262272"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262275"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262277"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262279"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262281"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262283"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262285"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262287"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262289"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262291"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262293"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262296"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262298"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262301"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262303"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262306"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262309"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262312"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262315"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262318"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262321"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262325"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262328"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262331"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262334"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262338"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262346"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262349"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262353"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262355"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262357"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262359"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262361"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262363"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262365"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262367"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262369"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262371"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262373"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262375"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262377"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262379"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262381"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262383"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262385"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262389"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262391"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262393"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262396"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262398"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262400"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262403"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262407"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262409"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262410"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262412"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262414"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262416"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262418"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262420"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262424"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262426"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262428"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262430"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262432"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262434"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262436"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262438"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262440"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262442"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262444"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262446"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262448"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262450"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262452"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262454"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262456"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262460"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262638"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262644"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262646"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262648"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262650"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262652"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262654"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262656"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262658"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262660"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262662"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262664"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262666"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262670"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262672"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262674"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262676"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262678"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262680"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262682"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262684"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262686"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262687"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262689"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262691"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262695"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262697"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262699"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262701"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262703"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262705"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262709"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262711"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262713"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262715"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262717"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262719"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262721"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262723"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262725"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262727"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262729"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262731"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262733"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262735"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262739"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262741"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262743"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262745"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262747"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262750"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262752"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262754"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262756"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262758"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262760"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262762"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262764"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262766"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262768"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262770"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262772"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262774"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262778"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262780"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262782"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262784"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262786"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262788"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262790"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262792"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262794"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262796"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262798"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262800"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262802"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262806"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262809"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262811"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262813"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262815"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262817"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262819"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262821"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262823"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262825"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262827"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262829"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262831"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262833"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262835"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262837"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262839"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262841"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262843"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262848"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262850"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262852"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262854"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262856"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262858"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262860"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262864"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262866"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262868"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262869"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262871"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262873"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262875"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262879"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262881"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262883"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262885"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262887"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262889"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262891"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262893"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262895"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262897"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262899"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262901"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262903"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262905"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262907"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262910"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262912"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262914"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262919"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262921"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262923"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262925"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262927"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262929"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262931"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262933"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262935"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262937"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262939"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262941"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262943"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262947"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262949"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262951"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262953"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262955"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262956"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262958"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262960"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262962"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262964"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262966"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262968"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262972"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262974"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262976"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262978"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262980"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262982"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262986"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262988"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262990"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262992"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262994"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262996"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.262998"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263000"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263001"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263004"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263006"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263008"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263010"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263012"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263016"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263018"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263020"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263049"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263051"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263053"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263058"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263060"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263062"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263064"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263066"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263068"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263070"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263072"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263074"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263076"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263078"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263080"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263084"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263086"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263088"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263090"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263092"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263094"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263096"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263098"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263100"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263102"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263104"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263106"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263108"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263110"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263116"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263118"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263120"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263122"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263124"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263126"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263127"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263129"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263131"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263133"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263135"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263137"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263139"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263141"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263146"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263148"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263150"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263152"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263156"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263158"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263160"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263162"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263164"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263166"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263168"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263179"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263181"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263183"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263185"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263187"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263189"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263191"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263196"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263198"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263200"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263202"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263204"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263205"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263207"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263209"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263211"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263213"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263215"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263217"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263219"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263221"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263223"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263225"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263227"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263229"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263235"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263237"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263239"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263243"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263245"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263247"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263249"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263251"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263253"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263255"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263257"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263259"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263261"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263265"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263267"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263269"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263271"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263273"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263275"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263277"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263279"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263281"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263283"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263285"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263287"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263289"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263293"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263295"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263296"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263298"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263300"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263302"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263306"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263308"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263310"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263312"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263314"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263316"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263318"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263320"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263322"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263324"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263326"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263328"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263330"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263333"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263335"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263337"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263339"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263341"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263344"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263346"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263350"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263352"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263354"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263356"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263358"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263359"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263361"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263363"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263365"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263367"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263369"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263371"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263375"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263377"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263379"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263381"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263383"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263385"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263387"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263391"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263394"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263397"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263401"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263404"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263406"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263415"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263418"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263422"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263425"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263428"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263432"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263435"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263437"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263439"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263441"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263443"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263445"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263447"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263449"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263451"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263453"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263455"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263457"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263458"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263463"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263465"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263467"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263469"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263470"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263472"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263476"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263478"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263480"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263482"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263484"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263486"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263488"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263492"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263494"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263496"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263498"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263500"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263502"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263503"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263505"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263507"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263509"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263511"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263513"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263515"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263517"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263519"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263521"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263523"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263525"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263527"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263534"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263536"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263538"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263540"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263542"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263544"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263546"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263548"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263550"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263552"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263554"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263556"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263560"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263562"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263564"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263566"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263568"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263570"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263571"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263573"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263575"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263577"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263579"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263581"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263583"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263585"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263589"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263591"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263593"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263595"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263597"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263600"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263602"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263604"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263606"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263608"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263610"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263612"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263614"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263616"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263618"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263620"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263622"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263624"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263628"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263630"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263632"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263634"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263635"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263638"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263639"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263643"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263645"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263647"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263649"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263651"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263653"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263655"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263657"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263659"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263661"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263663"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263665"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263669"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263671"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263673"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263675"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263677"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263679"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263681"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263683"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263684"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263686"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263688"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263690"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263692"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263698"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263700"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263702"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263704"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263706"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263708"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263710"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263712"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263714"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263715"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263717"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263719"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263721"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263723"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263725"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263727"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263729"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263731"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263733"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263737"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263739"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263741"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263743"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263745"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263747"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263749"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263752"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263754"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263756"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263758"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263760"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263762"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263766"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263768"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263770"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263772"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263774"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263776"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263778"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263780"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263782"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263784"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263786"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263788"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263790"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263792"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263794"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263796"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263797"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263799"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263801"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263805"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263809"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263811"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263813"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263814"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263817"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263818"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263820"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263822"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263824"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263826"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263828"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263834"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263836"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263838"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263840"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263855"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263857"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263859"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263861"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263863"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263865"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263867"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263868"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263870"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263872"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263876"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263878"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263880"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263882"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263884"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263886"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263890"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263892"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263894"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263896"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263897"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263899"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263903"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263905"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263907"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263909"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263911"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263913"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263917"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263919"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263921"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263923"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263925"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263927"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263929"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263932"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263934"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263937"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263939"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263941"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263942"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263944"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263946"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263948"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263950"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263952"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263954"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263956"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263960"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263962"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263964"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263966"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263968"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263970"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263972"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263973"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263975"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263977"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263979"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263981"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263985"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263988"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263990"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263992"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263994"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263996"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.263998"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264000"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264002"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264004"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264006"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264008"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264010"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264012"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264014"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264016"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264017"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264019"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264021"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264030"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264034"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264036"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264038"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264040"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264042"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264044"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264046"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264050"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264052"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264053"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264055"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264057"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264061"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264063"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264065"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264067"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264069"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264071"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264073"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264075"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264077"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264079"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264081"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264083"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264085"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264087"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264089"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264091"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264093"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264095"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264097"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264099"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264104"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264106"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264108"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264110"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264112"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264114"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264116"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264118"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264120"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264122"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264124"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264128"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264130"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264132"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264134"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264136"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264137"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264139"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264141"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264147"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264149"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264151"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264153"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264155"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264157"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264163"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264165"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264167"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264168"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264170"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264172"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264177"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264178"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264180"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264182"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264184"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264186"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264188"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264190"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264192"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264194"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264196"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264198"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264202"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264204"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264206"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264208"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264210"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264212"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264214"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264216"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264220"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264222"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264224"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264226"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264228"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264230"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264232"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264234"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264236"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264238"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264239"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264242"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264245"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264247"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264249"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264251"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264253"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264255"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264257"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264259"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264261"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264263"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264265"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264267"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264271"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264273"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264277"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264279"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264281"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264283"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264285"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264287"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264289"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264291"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264293"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264296"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264298"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264300"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264302"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264304"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264306"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264308"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264310"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264312"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264316"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264318"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264320"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264322"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264324"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264326"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264328"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264332"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264334"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264336"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264337"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264339"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264343"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264345"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264347"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264349"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264351"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264353"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264355"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264357"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264359"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264361"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264363"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264365"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264367"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264369"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264371"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264373"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264375"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264377"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264379"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264380"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264386"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264388"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264390"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264392"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264395"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264398"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264400"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264402"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264404"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264406"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264408"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264412"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264414"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264416"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264417"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264420"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264421"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264423"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264425"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264427"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264429"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264432"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264433"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264435"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264437"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264439"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264443"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264445"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264447"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264449"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264451"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264453"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264457"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264459"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264460"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264462"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264464"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264466"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264468"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264470"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264472"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264475"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264479"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264487"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264490"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264493"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264496"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264500"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264503"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264507"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264510"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264513"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264518"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264520"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264522"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264524"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264526"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264529"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264530"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264532"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264534"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264536"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264538"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264540"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264551"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264553"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264555"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264557"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264559"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264561"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264563"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264565"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264567"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264569"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264571"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264575"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264577"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264580"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264582"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264584"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264586"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264588"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264590"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264592"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264594"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264596"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264598"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264600"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264602"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264604"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264606"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264608"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264610"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264612"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264614"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264616"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264619"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264621"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264623"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264625"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264627"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264629"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264633"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264635"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264637"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264639"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264641"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264645"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264647"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264649"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264651"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264983"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264987"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264989"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264991"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264993"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264995"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264997"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.264999"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265001"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265003"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265005"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265007"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265009"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265011"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265013"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265015"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265017"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265035"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265037"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265039"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265041"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265043"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265045"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265047"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265049"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265051"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265053"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265057"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265059"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265061"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265074"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265076"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265078"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265080"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265082"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265084"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265086"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265088"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265090"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265092"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265094"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265096"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265098"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265102"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265104"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265106"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265108"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265110"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265114"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265115"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265118"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265120"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265122"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265124"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265126"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265127"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265129"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265131"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265133"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265138"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265140"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265141"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265147"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265149"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265151"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265153"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265155"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265157"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265161"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265163"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265165"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265167"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265169"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265171"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265173"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265175"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265177"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265179"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265181"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265183"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265189"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265191"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265193"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265195"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265197"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265199"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265201"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265203"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265205"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265207"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265209"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265212"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265214"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265218"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265220"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265222"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265224"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265226"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265228"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265230"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265232"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265234"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265236"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265238"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265240"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265242"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265244"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265246"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265248"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265250"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265252"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265254"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265258"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265260"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265262"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265264"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265266"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265268"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265270"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265274"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265276"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265278"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265280"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265283"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265285"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265287"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265289"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265291"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265293"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265295"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265297"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265299"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265301"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265303"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265305"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265307"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265309"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265311"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265313"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265315"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265317"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265318"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265320"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265322"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265326"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265330"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265332"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265334"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265336"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265338"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265340"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265342"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265344"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265346"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265350"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265352"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265353"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265355"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265357"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265359"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265361"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265363"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "expert",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265365"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265367"
    }
  },
  {
    "instruction": "Design a recommendation system for an e-commerce platform.",
    "input": "",
    "output": "Key components: User-item interaction matrix, collaborative filtering/content-based methods, ranking algorithms, and A/B testing. Cold-start problem needs hybrid approaches. Real-time performance requires caching.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265369"
    }
  },
  {
    "instruction": "How would you build a content moderation system?",
    "input": "",
    "output": "Combine text classification (detect harmful content), image recognition, and user reporting. Use ensemble models for robustness. Need rapid inference (<100ms) and human review workflow.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265371"
    }
  },
  {
    "instruction": "Design a fraud detection system.",
    "input": "",
    "output": "Use supervised learning on transaction history. Features: transaction amount, merchant, location, user behavior patterns. Real-time scoring with fast decision boundaries (<50ms latency) essential.",
    "domain": "ai_ml",
    "category": "ai_system_design",
    "difficulty": "hard",
    "metadata": {
      "generated_at": "2025-12-08T14:18:45.265373"
    }
  }
]